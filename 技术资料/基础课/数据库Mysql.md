# 数据库理论部分

数据库：

SQL

理论部分

MYSQL

REDIS

这四个大板块 

##### 理论部分：

- 四大范式（前三个重要）✅
- 数据库事务的特性 ACID ✅
- 数据库事务的四大隔离级别以及出现的问题 ✅
- MVCC，多版本并发控制，是提交读和可重复读的根本
- 数据库的锁（读写，共享排他，悲观乐观） ✅
- SQL与NOSQL，SQL其实就是结构化语言，也是一种事务

##### MySQL部分：

- 数据库索引及优化 ✅ 优化就是选什么字段用索引，然后什么时候索引会失效不能这么用
- 索引的底层实现：B-Tree B+Tree Hash BitMap这些底层实现结构
- 查询优化？
- 数据库 存储引擎层InnoDB和MyIsasm，服务层其实就是做个接口 ✅
- 数据库与分布式：主从复制，水平切分与垂直切分，日志 这是分布式数据库要学的

##### Redis部分：



### 基本概念整理： 主属性 主键 超键 候选键等

### 三大范式 ✅

##### 第一范式

- 官方：当关系模式R的所有属性都不能在分解为更基本的数据单位时，称R是满足第一范式的，简记为1NF。
- 理解：每一列属性都是不可再分的属性值，确保每一列的原子性。

##### 第二范式

- 官方：满足1NF后，要求表中的所有列，都必须依赖于主键，而不能有任何一列与主键没有关系；
- 理解：一张表只做一件事情。

##### 第三范式

- 官方：必须先满足第二范式（2NF），且表中的每一列只与主键直接相关而不是间接相关；
- 理解：表中的每一列只能依赖于主键。

这也是数据库设计准则

### 其他链接

##### https://blog.csdn.net/u013630349/article/details/50724244



# 数据库事务

​	数据库管理系统中事务(transaction)的四个特性（分析时根据首字母缩写依次解释）：原子性（Atomicity）、一致性（Consistency）、隔离性（Isolation）、持久性（Durability）。

​	所谓事务，它是一个**操作序列，这些操作要么都执行，要么都不执行，它是一个不可分割的工作单位**（执行单个逻辑功能的一组指令或操作称为事务）。

```
原子性  事务的原子性是指一个事务要么全部执行，要么不执行。不可能执行一半就停止了，遇到这种情况会回滚rollback
一致性  事务的运行并不改变数据库中数据的一致性，比如a与b之间有某种关系限制，事务改变了a，也势必会改变b
独立性 两个以上的食物不会出现交错执行的状态，因为这样可能导致数据不一致
```



### 事务是什么 ✅

事务是一个不可分割的数据库操作序列，也是数据库并发控制的基本单位，其执行结果必须使数据库从一种一致性的状态变到另一种一致性的状态。

### 事务的特征 ✅

数据库管理系统中事务(transaction)的四个特性（分析时根据首字母缩写依次解释）：原子性（Atomicity）、一致性（Consistency）、隔离性（Isolation）、持久性（Durability）。

​	所谓事务，它是一个**操作序列，这些操作要么都执行，要么都不执行，它是一个不可分割的工作单位**（执行单个逻辑功能的一组指令或操作称为事务）。

##### **原子性(Atomicity)**

​	原子性是指事务是一个不可再分割的工作单元，事务中的操作要么都发生，要么都不发生。

​	在DBMS中，默认情况下**一条SQL就是一个单独事务**，事务是**自动提交**的。只有显式的使用**start transaction**开启一个事务，才能将一个代码块放在事务中执行。

##### 一致性(**Consistency**)

​	一致性是指在**事务开始之前和事务结束以后**，**数据库的完整性约束没有被破坏**。这是说数据库事务不能破坏**关系数据的完整性**以及**业务逻辑上的一致性**。

​	如A给B转账，不论转账的事务操作是否成功，其两者的存款总额不变（这是业务逻辑的一致性，至于数据库关系约束的完整性就更好理解了）。

##### 隔离性(**Isolation**)

> 所以这里涉及了一个事务的隔离级别的问题

​	**多个事务并发访问时，事务之间是隔离的**，一个事务不应该影响其它事务运行效果。

​	在并发环境中，当不同的事务同时操纵相同的数据时，每个事务都有各自的完整数据空间。由并发事务所做的修改必须与任何其他并发事务所做的修改隔离。事务查看数据更新时，数据所处的状态要么是另一事务修改它之前的状态，要么是另一事务修改它之后的状态，**事务不会查看到中间状态的数据**。

​	事务最复杂问题都是由事务隔离性引起的。**完全的隔离性是不现实的，完全的隔离性要求数据库同一时间只执行一条事务**，这样会严重影响性能。

##### 持久性(**Durability**)

​	这是最好理解的一个特性：持久性，意味着在事务完成以后，**该事务所对数据库所作的更改便持久的保存在数据库之中，并不会被回滚。**（完成的事务是**系统永久的部分**，对系统的影响是永久性的，该修改即使出现致命的系统故障也将一直保持）

额外补充：write ahead logging：SQL Server中使用了WAL（Write-Ahead Logging）技术来保证事务日志的ACID特性，在数据写入到数据库之前，先写入到日志，再将日志记录变更到存储器中。

> 这里就涉及到数据库的主从复制问题了

### 事务并发带来的问题 ✅

##### 脏读

一个事务读取了另一个事务未提交的数据，即一个事务读取了另一个事务正在修改的值，已经改变的值

##### 不可重复读

不可重复读的重点是修改，同时条件下两次读取结果不同，也就是说被读区的数据可以被其他事务修改

##### 幻读

幻读 是事务非独立执行出现的问题，也就是在一个事务读的过程中，幻读的重点在于新增或者删除，同样条件下两次读出来的记录数不一样

幻读和不可重复读，都是读了其他事务已经提交的数据。
幻读和不可重复读都是读取了另一条已经提交的事务（这点与脏读不同），所不同的是不可重复读查询的都是同一个数据项，而幻读针对的是数据记录插入/删除问题，二者关注的问题点不太相同。

### 数据库事务的隔离级别 ✅

##### Serializable (串行化)

ERIALIZABLE（可串行化）：SERIALIZABLE是最高的隔离级别，它通过强制事务串行执行（注意是串行），避免了前面的幻读情况（**实际是读用读锁，写用写锁，读锁和写锁互斥，这么做可以有效的避免幻读、不可重复读、脏读等问题**）由于他大量加上锁，导致大量的请求超时，因此性能会比较底下，再特别需要数据一致性且并发量不需要那么大的时候才可能考虑这个隔离级别。不然ReadWriteLock 读写分离，读锁是共享的，也会出现问题

最高级别，可避免脏读、不可重复读、幻读的发生；//此时并发事务将串行执行，任何事务都不可能同步执行了 无论增删改查

##### Repeatable read (可重复读)

对数据项，加了行锁，可避免脏读、不可重复读的发生；//一旦一个事务对该数据发生读取操作，另一个事务就不可以修改，相当于对该数据项进行加锁

REPEATABLE READ（可重复读）：当隔离级别设置为Repeatable read时，可以避免不可重复读。**在可重复读中，该sql第一次读取到数据后，就将这些数据加锁（悲观锁），其它事务无法修改这些数据，就可以实现可重复读了**。**但这种方法却无法锁住insert的数据，所以当事务A先前读取了数据，或者修改了全部数据，事务B还是可以insert数据提交，这时事务A就会发现莫名其妙多了一条之前没有的数据**，这就是**幻读（针对的是记录总量）**，不能通过行锁来避免。

**MySQL中InnoDB的默认隔离级别就是Repeatable read。**



##### Read committed (读已提交)

可避免脏读的发生；就是 未提交的时候 你看不到别人的数据

READ COMMITTED（提交读）大多数数据库系统（比如Sql Server , Oracle）的默认隔离级别是READ COMMITTED，**这种隔离级别就是一个事务的开始，只能看到已经完成的事务的结果，正在执行的，是无法被其他事务看到的**。这种级别会出现读取旧数据（不可重复读）的现象，**事务A先读取了数据，事务B紧接了更新了数据，并提交了事务，而事务A再次读取该数据时，数据已经发生了改变。**

##### Read uncommitted (读未提交)

READ UNCIMMITTED（未提交读）：**事务中对数据的修改，即使没有提交，其他事务也可以看得到**，这种隔离级别会引起很多问题，如无必要，不要随便使用。

最低级别，任何情况都无法保证，事务中对数据的修改，即使没有提交，其他事务也看得到

隔离级别越高，安全性越高，执行效率也就越低





# 逻辑架构 ✅

**如果让我们来设计一个关系型数据库，我们可能这样设计：**

存储管理

缓存机制

SQL解析（一条SQL就是一个事务，涵盖事务的四大特性）

日志管理

索引管理

锁管理

权限划分 容灾机制 

![](/Users/Haoyu/Documents/typora/%E6%95%B0%E6%8D%AE%E5%BA%93/assets/%E5%85%B3%E7%B3%BB%E5%9E%8B%E6%95%B0%E6%8D%AE%E5%BA%93%E8%AE%BE%E8%AE%A1.png)

实际的逻辑结构图如下：

![](/Users/Haoyu/Documents/typora/%E6%95%B0%E6%8D%AE%E5%BA%93/assets/mysql%E9%80%BB%E8%BE%91%E6%9E%B6%E6%9E%84.png)

​	其逻辑结构分为四层，如下：

### Connectors连接层

​	Connectors连接层是一些客户端和连接服务，包含本地的socket通信和大多数基于客户端/服务端工具实现的类似于tcp/ip的通信，主要完成一些类似于连接处理、授权认证及相关的安全方案，在该层上引用了线程池的概念，为通过认证安全接入的客户端提供线程。同样在该层上可以实现基于ssl的安全链接。服务器也会为安全接入的每个客户端验证它所具有的操作权限。

>  数据库线程池和Java线程池也是一样的，减少线程创建和销毁的CPU开销

### 第二层（服务层）

​	第二层架构主要完成大多数的核心服务功能。如sql接口，并完成缓存的查询。sql的分析和优化 以及部分内置函数的执行。所有跨存储引擎的功能也在这一层实现，如过程，函数等。在该层，服务器会解析查询并创建相应的内部解析树，并对其完成相应的优化如确定查询表的顺序，是否利用索引等。最后生成相应的执行操作。如select语句，服务器还会查询内部的缓存。

**如果缓存空间足够大，这样就解决大量读操作的环境中能够很好的提升系统的性能。**

//读操作真的是很依赖缓存，缓存提高命中率，这样读操作基本是常数级时间复杂度



​	其中各部分功能如下：

- Manager Services & Utilities：系统管理和控制工具
- Connection Pool：

​	管理缓冲用户连接，线程处理等需要缓存的需求。

​	负责监听对 MySQL Server 的各种请求，接收连接请求，转发所有连接请求到线程管理模块。每一个连接上 MySQL Server 的客户端请求都会被分配（或创建）一个连接线程为其单独服务。而连接线程的主要工作就是负责 MySQL Server 与客户端的通信，
​	接受客户端的命令请求，传递 Server 端的结果信息等。线程管理模块则负责管理维护这些连接线程。包括线程的创建，线程的 cache 等。

- SQL interface：接受用户的SQL命令，并且返回用户需要查询的结果。比如select from就是调用SQL Interface
- Parser：

​	SQL命令传递到解析器的时候会被解析器验证和解析。解析器是由Lex和YACC实现的，是一个很长的脚本。

​	在 MySQL中我们习惯将所有 Client 端发送给 Server 端的命令都称为 query ，在 MySQL Server 里面，连接线程接收到客户端的一个 Query 后，会直接将该 query 传递给专门负责将各种 Query 进行分类然后转发给各个对应的处理模块。
​	主要功能：
​	a . 将SQL语句进行语义和语法的分析，分解成数据结构，然后按照不同的操作类型进行分类，然后做出针对性的转发到后续步骤，以后SQL语句的传递和处理就是基于这个结构的。
​	b.  如果在分解构成中遇到错误，那么就说明这个sql语句是不合理的

- Optimizer：

​	SQL语句在查询之前会使用查询优化器对查询进行优化。就是优化客户端请求的 query（sql语句） ，根据客户端请求的 query 语句，和数据库中的一些统计信息，在一系列算法的基础上进行分析，得出一个最优的策略，告诉后面的程序如何取得这个 query 语句的结果。如“选取-投影-联接”策略进行查询。
​	用一个例子就可以理解： select uid,name from user where gender = 1；
​        这个select 查询先根据where 语句进行选取，而不是先将表全部查询出来以后再进行gender过滤；
​        这个select查询先根据uid和name进行属性投影，而不是将属性全部取出以后再进行过滤；
​        将这两个查询条件联接起来生成最终查询结果。

- Caches & Buffers：

​	主要功能是将客户端提交 给MySQL 的 Select 类 query 请求的返回结果集 cache 到内存中，与该 query 的一个 hash 值做一个对应。该 Query 所取数据的基表发生任何数据的变化之后， MySQL 会自动使该 query 的Cache 失效。**（violate 关键字，可见性）**

在读写比例非常高的应用系统中， Query Cache 对性能的提高是非常显著的。当然它对内存的消耗也是非常大的，读操作十分多的应用系统中。

​	如果查询缓存有命中的查询结果，查询语句就可以直接去查询缓存中取数据。这个缓存机制是由一系列小缓存组成的。比如表缓存，记录缓存，key缓存，权限缓存等。

### 存储引擎层

存储引擎真正的负责MySQL中数据的存储和提取，服务器通过API与存储引擎进行通信，不同的存储引擎具有的功能不同，这样我们可以根据自己的实际需进行选取。注意：

**存储引擎是基于表的，而不是数据库**。

### 数据存储层

主要是将数据存储在运行于裸设备的文件系统之上，并完成于存储引擎的交互。

完成与存储引擎的交互。



# 存储引擎

### MyISAM

​	该引擎是MySQL5.5版本之前使用的默认存储引擎。

- 在索引方面，其使用聚簇索引；
- 在锁方面，其只支持表级锁。

##### MyISAM适合的场景：

- 全表频繁执行count语句

  ​	InnoDB存储引擎不保存表的具体行数，执行`select count(*) from table`时，需要重新扫描统计表中数据。

  myisam中则使用一个变量记录了表中数据量，执行`select count(*) from table`时，只需要直接读出该变量即可。

- 对数据进行增删改的频率不高，查询非常频繁地情况 因为使用了聚簇索引，在物理上是连续的？

  ​	因为增删改会涉及到锁表操作，虽然插入操作可以通过一些配置支持从表的尾部插入数据，但是依然会产生很多碎片，比较影响性能。

- 适合没有事务的场景

因为MyISAM不支持事务，但是支持表级锁

### InnoDB

​	该引擎是MySQL5.5版本之后使用的默认存储引擎，然后开始支持事务。

- 在索引方面，其使用的是非聚簇索引；

- 在锁方面，其默认使用的是行级锁，也支持行级锁。

  

##### InnoDB适用的场景：

- 数据增删改查都相当频繁；

  ​	因为使用的是行级锁，在增删改时，只有某些行被锁住，而不像MyISAM，每次都是整张表被锁住，这样大大提高了并发性。

- 可靠性要求比较高，要求支持事务



# 数据库索引

### 是什么

##### 简介

​	是帮助MySQL高效获取数据的数据结构（排好序的快速查找数据结构），类似于字典，我们使用字典的时候想要查某个字，实际上是通过字典的偏旁部首查字表或者拼音查字表进行快速定位，这些偏旁部首查字表和拼音查字表就是索引。

##### 以 二叉查找树为例

​	在数据之外，**数据库系统还维护着满足特定查找算法的数据结构**，这些结构以某种方式引用（指向）数据，这样就可以在这些数据结构上实现高效查找算法。这种数据结构，就是索引。下图就是一种可能的索引方式(二叉查找树)：

![](/Users/Haoyu/Documents/typora/%E6%95%B0%E6%8D%AE%E5%BA%93/assets/%E7%B4%A2%E5%BC%95.png)

​	左边是数据表，一共有两列七条记录，最左边的是数据记录的物理地址（注意逻辑上相邻的记录在磁盘上也并不是一定物理相邻的）。**为了加快Col2的查找，可以维护一个右边所示的二叉查找树，<font color="red">每个节点分别包含索引键值和一个指向对应数据记录物理地址的指针</font>，这样就可以运用二叉查找在O(log2n)的复杂度内获取到相应数据。**

​	物理地址，记录序号，以及数据值，结点中要存索引的键值，和一个指向对应数据记录物理地址的指针

​	其实际图像如下：

![](/Users/Haoyu/Documents/typora/%E6%95%B0%E6%8D%AE%E5%BA%93/assets/%E4%BA%8C%E5%8F%89%E6%9F%A5%E6%89%BE%E6%A0%91.png)

​	但一般来说索引本身也很大，不可能全部存储在内存中，因此索引往往是以索引文件的形式存储在磁盘上。

​	linux开发，所有的东西，都可以看作是文件

​	Java 开发中所说的索引，通常指的都是B 树 (多路搜索树，并不一定是二叉的) 结构组织的索引。

其中聚集索引、次要索引、复合索引、前缀索引、唯一索引**默认使用的都是 B+ 树索引**。

除了 B+ 树索引这种类型外，还有哈希(Hash)索引。

### Mysql索引的种类？✅

##### 聚簇索引和非聚簇索引

聚簇索引的顺序就是数据的物理存储顺序；
索引顺序与数据物理排列顺序无关。

- 因此 一个表最多有一个聚簇索引，聚簇索引的叶结点就是数据节点，而非聚簇索引的叶结点仍然是索引节点，只不过有一个指针指向对应的数据块。
- 聚簇索引确定表中数据的物理顺序，聚簇索引对于那些经常要搜索范围值的列特别有效。使用聚簇索引找到包含第一个值的行后，便可以确保后续索引值的行物理相邻。

非聚簇索引，索引中的项目按索引键值的顺序存储，而表中的信息按另一种顺序存储，所以在索引中要加入指向键值物理地址的指针。

##### 普通索引和唯一索引

索引列的值的唯一性 比如主键就是唯一索引的特殊类型，创建主键的时候，数据库默认会为主键创建一个唯一索引，

普通索引，MYSQL中基本索引类型，没有什么限制，允许在定义索引的列中插入重复值和空值

纯粹为了查询数据更快一点

唯一索引，索引列中的值必须是唯一的，但是允许为空值

主键索引，是一种特殊的唯一索引，不允许有空值，其实创建主键的时候，就会默认创建一口索引，主键约束，就是主键索引

##### 单个索引和复合索引（或者组合索引）

索引列包含的列数

##### mysql复合（组合、联合）索引，最左匹配原则

对于多列索引，必须满足 最左匹配原则即查询条件中

其实就和查字典类似，你首先要匹配最左的字母，a 才能继续往下匹配比如 ao等

 (eg：多列索引col1、col2和col3，则 索引生效的情形包括 col1或col1，col2或col1，col2，col3)。

### 优势与劣势 ✅

优势：

- 类似于大学图书馆书目索引，**提高数据检索的效率**，降低数据库的io成本
- 通过索引列对数据进行排序，**降低数据排序的成本**，降低了 CPU 的消耗

劣势：

空间问题 和 有频繁插入的时间效率上 会出现问题。

- 实际上索引也是一张表，该表保存了主键和索引字段，并指向实体表的记录，所以索引列也是要占用空间的。
- 虽然索引大大提高查询速度，但同时也会降低更新表的速度，如对表进行insert, update和delete操作。因为更新表时，MySQL 不仅要保存数据，还要保存一下索引文件每次更新添加了索引列的字段。

### 创建索引的时候要注意什么

- 取离散大的值放在组合索引的前面，左侧，是因为，数据稠密度小 否则树可能会比较深

```
1.非空字段：应该指定列为NOT NULL，除非你想存储NULL。在mysql中，含有空值的列很难进行查询优化，因为它们使得索引、索引的统计信息以及比较运算更加复杂。
你应该用0、一个特殊的值或者一个空串代替空值；

2.取值离散大的字段：（变量各个取值之间的差异程度）的列放到联合索引的前面，
可以通过count()函数查看字段的差异值，返回值越大说明字段的唯一值越多字段的离散程度高；

3.索引字段越小越好：数据库的数据存储以页为单位一页存储的数据越多一次IO操作获取的数据越大效率越高。
这也是为什么用B+树不用B树的原因
```

### 以及什么样的字段适合创建索引？

其实都是经常被使用的字段

- 经常作选择查询的字段
- 经常作表连接的字段
- 经常出现在order by， group by，distinct的字段后面



### 建索引的命令语句

##### 创建

```mysql
CREATE [UNIQUE] INDEX indexName ON tableName(columnName(length));

ALTER tableName ADD [UNIQUE] INDEX [indexName] ON (columnName(length));

# 注：添加主键约束、唯一索引也属于添加索引，
# 不过主键约束属于约束，其中一定包含了唯一索引且不允许有 null
# 而唯一索引则允许有 null
```

##### 删除

```mysql
DROP INDEX [indexName] ON tableName;
```

##### 查看

```mysql
SHOW INDEX FROM tableName;
```



### 什么情况下不使用索引	✅

1. 时间方面：创建索引和维护索引要耗费时间，具体地，当对表中的数据进行增加、删除和修改的时候，索引也要动态的维护，这样就降低了数据的维护速度；

2. 空间方面：索引需要占物理空间。
   因此我觉得不使用索引的情况，是数据量并没有想象那么大，创建和维护索引（增删改频繁）相对来说开销较大的时候。

3. 再一个就是，也和我自身的任务有关系，比如我本身的任务就是遍历，检索所有数据，将所有数据读出来，用索引反而要先扫描索引再去扫描所有界面，就有点多余。

### **索引失效**

1. 以“%(表示任意0个或多个字符)”开头的LIKE语句，模糊匹配；
2. OR语句前后没有同时使用索引；
3. 数据类型出现隐式转化（如varchar不加单引号的话可能会自动转换为int型）；
4. 对于多列索引，必须满足 最左匹配原则 (eg：多列索引col1、col2和col3，则 索引生效的情形包括 col1或col1，col2或col1，col2，col3)。按次，先根据第一个关键字来筛选嘛，所以就出现了最左匹配的原则。



### 没有索引的情况下如何快速查询

```

```

### 索引的实现

B+树的性质：
所有的叶子结点中包含了全部关键码的信息，及指向含有这些关键码记录的指针，且叶子结点本身依关键码的大小自小而大的顺序链接；
非终端结点可以看成是索引部分，节点中仅含有其子树根结点中最大（或最小）关键码

### 索引结构的分类

- B-Tree索引
- Hash 索引
- Full-text 全文索引
- R -Tree 索引
- BitMap索引

##### 二叉查找树索引

在本篇开头的时候介绍过了，二叉查找树

##### B-Tree索引 ✅

该索引结构如下：

![](../assets/B%E6%A0%91.png)

![](../assets/mysqlB+Tree%E7%B4%A2%E5%BC%95%E7%BB%93%E6%9E%84.png)

​	如上图，是一颗b树，浅蓝色的块我们称之为一个磁盘块，可以看到每个磁盘块包含几个数据项（深蓝色所示）和指针（黄色所示），如磁盘块1包含数据项17和35，包含指针P1、P2、P3，P1表示小于17的磁盘块，P2表示在17和35之间的磁盘块，P3表示大于35的磁盘块。

**真实的数据存在于叶子节点**即3、5、9、10、13、15、28、29、36、60、75、79、90、99。非叶子节点只不存储真实的数据，只存储指引搜索方向的数据项，如17、35并不真实存在于数据表中。

其查找过程如下：

​	如图所示，如果要查找数据项29，那么首先会把磁盘块1由磁盘加载到内存，此时发生一次IO，在内存中用二分查找确定29在17和35之间，锁定磁盘块1的P2指针，内存时间因为非常短（相比磁盘的IO）可以忽略不计，通过磁盘块1的P2指针的磁盘地址把磁盘块3由磁盘加载到内存，发生第二次IO，29在26和30之间，锁定磁盘块3的P2指针，通过指针加载磁盘块8到内存，发生第三次IO，同时内存中做二分查找找到29，结束查询，总计三次IO。

​	真实的情况是，3层的b+树可以表示上百万的数据，如果上百万的数据查找只需要三次IO，性能提高将是巨大的，如果没有索引，每个数据项都要发生一次IO，那么总共需要百万次的IO，显然成本非常非常高。

​	以上查找过程也解释了**为什么要使用索引**，一般来说，索引本身也很大，不可能全部存储在内存中，因此索引往往以索引文件的形式存储的磁盘上，查找过程也增加了io消耗，但相较于没有索引情况下逐个搜索，性能提升巨大。

索引本身也很大，所以，只能一个节点，一个磁盘块一个磁盘块的加载

##### B+Tree索引

- 该索引结构如下：

  ![](../assets/B+%E6%A0%91.png)

![](../assets/B+Tree%20%E7%BB%93%E6%9E%84.png)

- 说明：
  - 非叶子节点仅用来索引，所有的数据都保存在叶子节点中，但是非叶子结点也是数据项，不是b-tree中仅仅指引方向
  - 所有的叶子节点均有一个链指针指向下一个节点（方便做统计），方便做遍历吧，TreeMap和HashMap以及HashSet
  - 非叶子节点的子树指针与关键字个数相同
  - 非叶子节点的子树指针指向关键字值在一定范围内的子树，由图观察规律，写出来还不如直接观察。
- 使用B+树做索引的优点：
  - B+树的磁盘读写代价更低
  - B+树的查询效率（查询时间都是log(n)）更稳定
  - B+树更有利于对数据库的扫描

##### 

### 数据库索引为什么用b+树

B+树相对于B树来说
1.B+tree的磁盘读写代价更低，因为所有的信息都在叶子节点存着，并且叶子结点之间还以链表的形式互相连接
B+tree的内部结点 叶子结点有并没有指向关键字具体信息的指针(红色部分)，不指向关键字具体信息
因此其内部结点相对B 树更小。如果把所有同一内部结点的关键字存放在同一盘块中，那么盘块所能容纳的关键字数量也越多。
一次性读入内存中的需要查找的关键字也就越多，相对来说IO读写次数也就降低了；
2.B+ Tree的查找效率更加稳定，由于内部结点并不是最终指向文件内容的结点，而只是叶子结点中关键字的索引，所以，任何关键字的查找必须走一条从根结点到叶子结点的路。
所有关键字查询的路径长度相同，导致每一个数据的查询效率相当；
3.数据库索引采用B+树，而不是B树的主要原因是，对于涉及范围的查找，或者说需要对整个树进行遍历，B+树只需对链表进行遍历，而B树需要中序遍历才行。

```
mysql在没有索引的情况下想达到快速查询
```





- B+Tree： 是InnoDB引擎的索引实现，不同的引擎正如不同版本的虚拟机

- 数据库连接池，如果开发中使用连接池发现可用连接数量不足，可能是什么原因？





# SQL优化

### SQL语句这里，也需要再看一下

##### 左外连接

##### 右外连接

# MVCC

# 数据库锁



### 概述 ✅ 

​	相对其他数据库而言，MySQL的锁机制比较简单，其最显著的特点是不同的存储引擎支持不同的锁机制。比如，MyISAM和MEMORY存储引擎采用的是表级锁（table-level locking）；InnoDB存储引擎既支持行级锁（ row-level locking），也支持表级锁，但默认情况下是采用行级锁。

### 隔离级别 ✅

​	事务的隔离级别有四种，隔离级别高的数据库的可靠性高，但并发量低，而隔离级别低的数据库可靠性低，但并发量高，系统开销小。可靠性由低到高依次为Read uncommitted、Read committed、Repeatable read、Serializable，这四个级别可以逐个解决脏读、不可重复读、幻读这几类问题。

√: 可能出现    ×: 不会出现

|                  | 脏读 | 不可重复读 | 幻读 |
| ---------------- | ---- | ---------- | ---- |
| Read uncommitted | √    | √          | √    |
| Read committed   | ×    | √          | √    |
| Repeatable read  | ×    | ×          | √    |
| Serializable     | ×    | ×          | ×    |

### 锁的分类 ✅

从锁的粒度划分：

- 表级锁：开销小，加锁快；

  不会出现死锁(因为MyISAM会一次性获得SQL所需的全部锁)；锁定粒度大，发生锁冲突的概率最高,并发度最低。

- 行级锁：开销大，加锁慢；行级锁开销大，加锁慢。

  会出现死锁；锁定粒度最小，发生锁冲突的概率最低,并发度也最高。

从锁级别上划分：

- **读锁(共享锁)**
- **写锁(排它锁)**
- 但是读锁与写锁 是互斥的

从使用方式上划分：

- 乐观锁
- 悲观锁

### 表级锁 ✅

##### 表级读锁、写锁

​	MyISAM 的默认是给表上表锁，而 InnoDB 既支持表锁，也支持行级锁，默认使用的是行级锁。

​	现在先来在MyISAM环境下对表锁进行测试。

​	假设数据库中表`person_info_myisam`中的数据量为2,500,000条，开启两个查询窗口模仿多线程查询情况：

​	窗口一：

```mysql
#该语句单独执行需要几秒钟
select * from person_info_myisam where id between 1 and 2000000;
```

​	窗口二：

```mysql
#该语句单独执行的速度很快
update person_info_myisam set account = account where id = 2000001;
```

​	如果窗口一中sql语句运行的同时同时让窗口二中的sql语句也运行，会发现窗口二中的sql语句运行也卡住，直到窗口一sql语句执行完毕，窗口二的语句才会执行完毕。

##### myisam 的自动加表锁机制 

​	**出现这样情况的原因是myisam使用的是表级锁，在执行 select 查询语句时，myisam会自动为表加上一个表级别的读锁，在执行增删改时，会自动为表加上一个表级别的写锁**。

- 当读锁未被释放时，另外的读操作也可以对表加上读锁，进行读操作，不会受到当前读锁的影响，但若操作想对表加上写锁时，就会自动被阻塞，直到所有的读锁都被释放为止**（共享锁）**；
- 当写锁未被释放时，另外所有想要加锁的操作都会被阻塞，直到当前写锁的释放**（排它锁）**。

##### 显式加锁

​	除了myisam的默认加锁，我们也可以对表进行显式加读锁或写锁。如下所示：

​	窗口一：

```mysql
lock tables person_info_myisam read;	# 加了读锁
lock tables person_info_myisam write;	# 也可以这么用
```

​	窗口二：

```mysql
update person_info_myisam set account = account where id = 2000001;
```

​	在执行完窗口一之后，再执行窗口二的语句时，会发现窗口二的语句一直处于阻塞状态，操作一直不成功。需要释放锁才可以。

```mysql
# 任意窗口，只要下面命令执行，窗口二的语句立马执行成功
unlock tables;
```

### 共享锁与排它锁 ✅

##### 共享锁

​	上述测试中的读锁都是共享锁，即可以多个事务同时进行查询操作，事务之间不会互斥。如下所示：

​	窗口一：

```mysql
#该语句单独执行需要几秒钟
select * from person_info_myisam where id between 1 and 2000000;
```

​	窗口二：

```mysql
#该语句单独执行的速度很快
select * from person_info_myisam where id = 2000001;
```

​	先执行窗口一再执行窗口二，与之前的update操作不同，窗口二立刻执行完毕，并不会因为窗口一中执行的语句而阻塞。

​	总结：上了共享锁之后依然支持上共享锁，不支持上排它锁。如当读锁未被释放时，另外的读操作也可以对表加上读锁，进行读操作，不会受到当前读锁的影响，但若操作想对表加上写锁时，就会自动被阻塞，直到所有的读锁都被释放为止**（共享锁）**；

**但是读、写锁是互斥的。**

##### 排它锁

​	总结：上了排它锁之后就不可以再加入其它的锁。当写锁未被释放时，另外所有想要加锁的操作都会被阻塞，直到当前写锁的释放**（排它锁）**。

​	注：读操作同样可以加上排它锁，如下所示：

```mysql
select * from person_info_myisam for update;
```

##### 共享锁和排它锁的兼容性

|             | 共享锁S | 排它锁X |
| :---------: | :-----: | :-----: |
| **共享锁S** |  兼容   |    ✘    |
| **排它锁X** |    ✘    |    ✘    |

### 乐观锁与悲观锁

##### 乐观锁

​	乐观锁主要通过版本号来实现，版本号有两种实现方式，分别如下：

- 添加版本号字段

  ​	一般是添加`int(3)`类型的`version`字段。如以下代码所示：

  ```mysql
  CREAT TABLE test(
    id int(2) NOT NULL AUTO_INCREMENT,
    money int(5) NOT NULL,
    version int(3) NOT NULL DEFAULT 0,
    PRIMARY KEY(id)
  ) ENGINE=InnoDB DEFAULT CHARSET=utf8;
  ```

  ​	数据每更新一次，就对version字段加一。当提交version信息时，就将数据库中的版本信息与当前version值进行比对，如果一致，则没有发生冲突，直接更新，如果不一致，则发生冲突，可采用自旋操作来尝试更新。

  也可以通过自旋的操作如CAS自旋变量那样，进行尝试更新

  ​	具体操作如下：

  ​	窗口一：

  ```mysql
  # 先获取version
  select version from test where id = 2;
  # 再更新money信息，更新的同时将version版本也更新
  update test set money = 123, version = 0 + 1 where version = 0 and id = 2;
  ```

  ​	窗口二：

  ```mysql
  # 先获取version
  select version from test where id = 2;
  # 再更新money信息，更新的同时将version版本也更新
  update test set money = 456, version = 0 + 1 where version = 0 and id = 2;
  ```

  ​	如上代码所示，当窗口一更新完毕时，窗口二提交update语句就会失败，这时的失败情况就交由开发者来自行处理。 所以这里Version 不一致，进而保证了互斥。

- 添加时间戳

##### 悲观锁

​	悲观锁在之前已经实现很多，在此不再赘述

之前所说的表锁，行锁，以及根据它们是否可以共享而分的类型，所以锁这块，烂熟于胸应该。

​	

### 乐观锁和悲观锁的具体理解

乐观锁，虽然名字中带“锁”，但是乐观锁并不锁住任何东西，
而是在提交事务时检查这条记录是否被其他事务进行了修改：如果没有，则提交；
否则，进行回滚。
相对于悲观锁，在对数据库进行处理的时候，乐观锁并不会使用数据库提供的锁机制。
如果并发的可能性并不大，那么乐观锁定策略带来的性能消耗是非常小的。
乐观锁采用的实现方式一般是记录数据版本。
乐观锁 其实就是重复写的策略

悲观锁，正如其名，它指的是对数据被外界修改持保守(悲观)态度，
因此，在整个数据处理过程中，将数据处于锁定状态。
悲观锁的实现往往依靠数据库提供的锁机制，也只有数据库层提供的锁机制才能真正保证数据访问的排他性，
否则即使在本系统中实现了加锁机制，也无法保证外部系统不会修改数据。
悲观锁的并发控制，实际上是先取锁，再访问的保守策略

### 悲观锁和乐观锁小结

1.悲观锁和乐观锁的思想上的不同
2.实现上的不同

# 数据库连接池